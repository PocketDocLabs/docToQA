{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list', 'data': [{'id': 'Meta-Llama-3-8B-Instruct-AWQ', 'object': 'model', 'created': 1713796466, 'owned_by': 'pygmalionai', 'root': 'Meta-Llama-3-8B-Instruct-AWQ', 'parent': None, 'permission': [{'id': 'modelperm-08e05603f36a4b689afaaa806ce7bfcb', 'object': 'model_permission', 'created': 1713796466, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}]}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "base_url = \"http://192.168.13.138:2242\"\n",
    "# Generate API URL\n",
    "# gen_url = \"http://192.168.13.53:8080/v1/completions\"\n",
    "# gen_url = \"http://192.168.13.138:2242/v1/completions\"\n",
    "\n",
    "# Token count API URL\n",
    "# token_count_url = \"http://192.168.13.53:8080/tokenize\"\n",
    "# token_count_url = \"http://192.168.138.73:2242/v1/token/encode\"\n",
    "\n",
    "# Generate API URL from the base URL\n",
    "gen_url = base_url + \"/v1/completions\"\n",
    "\n",
    "# Token count API URL from the base URL\n",
    "token_count_url = base_url + \"/v1/token/encode\"\n",
    "\n",
    "# Model list API URL from the base URL\n",
    "model_list_url = base_url + \"/v1/models\"\n",
    "\n",
    "\n",
    "# Function to get token count\n",
    "def token_count(text, send_ids=False):\n",
    "    # Set the headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Set the JSON\n",
    "    json = {\n",
    "                \"prompt\": text\n",
    "            }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.post(token_count_url, headers=headers, json=json)\n",
    "\n",
    "    # Expected response\n",
    "    # {'value': 28, 'ids': [3957, 13465, 3958, 369, 499, 5380, 70869, 25, 8489, 433, 14117, 627, 697, 33194, 18607, 25, 220, 17, 271, 3923, 374, 279, 6864, 315, 9822, 5380, 70869, 25]}\n",
    "\n",
    "    # Count the number of tokens\n",
    "    num_tokens = response.json()[\"value\"]\n",
    "\n",
    "    if send_ids:\n",
    "        return num_tokens, response.json()[\"ids\"]\n",
    "    else:\n",
    "        return num_tokens\n",
    "\n",
    "# Function to get the list of models\n",
    "def get_model_list():\n",
    "    # Send the request\n",
    "    response = requests.get(model_list_url)\n",
    "\n",
    "    # Return the response\n",
    "    return response.json()\n",
    "\n",
    "# Function to return the name of the first model\n",
    "def get_first_model_name():\n",
    "    # Get the list of models\n",
    "    model_list = get_model_list()\n",
    "\n",
    "    # Expected response\n",
    "    # {'object': 'list', 'data': [{'id': 'Meta-Llama-3-8B-Instruct-AWQ', 'object': 'model', 'created': 1713796466, 'owned_by': 'pygmalionai', 'root': 'Meta-Llama-3-8B-Instruct-AWQ', 'parent': None, 'permission': [{'id': 'modelperm-08e05603f36a4b689afaaa806ce7bfcb', 'object': 'model_permission', 'created': 1713796466, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}]}]}\n",
    "\n",
    "    # Get the name of the first model\n",
    "    first_model_name = model_list[\"data\"][0][\"id\"]\n",
    "\n",
    "    # Return the name of the first model\n",
    "    return first_model_name\n",
    "\n",
    "\n",
    "def get_completion(prompt, max_tokens=200, temperature=1.5, min_p=0.1, stop_sequence=[], regex=\"\"):\n",
    "\n",
    "    model = get_first_model_name()\n",
    "\n",
    "    # Set the headers\n",
    "    headers = {\n",
    "        \"X-API-KEY\": \"EMPTY\",\n",
    "    }\n",
    "\n",
    "    # Set the JSON\n",
    "    json = {\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"max_context_length\": 16000,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": temperature,\n",
    "                \"min_p\": min_p,\n",
    "                \"guided_regex\": regex,\n",
    "                \"stop\": stop_sequence\n",
    "            }\n",
    "    \n",
    "    # Expected response\n",
    "    \"\"\"\n",
    "    {'id': 'cmpl-3263575ebf6a4efb82d7bb8cba177a7b', 'object': 'text_completion', 'created': 844573, 'model': 'llama-3-70b-instruct', 'choices': [{'index': 0, 'text': \" What is the general overview of the ignition system in a vehicle?\\nClosed-ended question: Is the ignition system responsible for generating high voltage?\\nSemi-Structured question: Can you explain the difference between the Transistorised Coil Ignition (TCI) system and the Motronic ignition system?\\nLeading question: Don't you think that the ignition system is a critical component of a vehicle's engine?\\n\\nInstructions (Imperatives)\\n\\nShort instruction: Check the ignition system regularly to ensure proper engine performance.\\nScenario\", 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 9396, 'total_tokens': 9496, 'completion_tokens': 100}}\n",
    "    \"\"\"\n",
    "    # Send the request\n",
    "    response = requests.post(gen_url, headers=headers, json=json, timeout=600)\n",
    "\n",
    "    # Return the response\n",
    "    return response.json()\n",
    "\n",
    "def get_completion_text(prompt, max_tokens=200, temperature=1.0, min_p=0.2, stop_sequence=[\"<|eot_id|>\"], regex=\"\"):\n",
    "    return get_completion(prompt, max_tokens, temperature, min_p, stop_sequence, regex)[\"choices\"][0][\"text\"]\n",
    "\n",
    "# Get the list of models\n",
    "model_list = get_model_list()\n",
    "\n",
    "# Print the list of models\n",
    "print(model_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
