{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from structml import line_heal\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from rich.progress import track\n",
    "import tika\n",
    "tika.initVM()\n",
    "\n",
    "from tika import parser\n",
    "\n",
    "work_dir = \"./pdf_temp/\"\n",
    "\n",
    "pdf_path = \"/home/rstewart/Downloads/20120001369.pdf\"\n",
    "\n",
    "\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "# Delete all files in the work directory\n",
    "for filename in os.listdir(work_dir):\n",
    "    file_path = os.path.join(work_dir, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def split_pdf_into_pages(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        for i in range(num_pages):\n",
    "            pdf_writer = PyPDF2.PdfWriter()\n",
    "            pdf_writer.add_page(pdf_reader.pages[i])\n",
    "            \n",
    "            output_filename = f'page_{i+1}.pdf'\n",
    "            with open(work_dir + output_filename, 'wb') as output_pdf:\n",
    "                pdf_writer.write(output_pdf)\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    raw_text = \"\"\n",
    "\n",
    "    parsed_pdf = parser.from_file(pdf_path)\n",
    "\n",
    "    if parsed_pdf['content']: # type: ignore\n",
    "        raw_text = parsed_pdf['content'] # type: ignore\n",
    "    \n",
    "    # Strip leading and trailing whitespace\n",
    "    raw_text = raw_text.strip()\n",
    "\n",
    "    # Replace muktiple newlines with a single newline\n",
    "    raw_text = re.sub(r'\\n+', '\\n', raw_text)\n",
    "\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "split_pdf_into_pages(pdf_path)\n",
    "\n",
    "output_text = []\n",
    "\n",
    "# Extract text from each page and add it to a dictionary with the keys being the page number and the values being the text split into lines (as a list)\n",
    "for filename in track(os.listdir(work_dir)):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        page_number = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "        \n",
    "        # Split the text into lines and add it to the dictionary\n",
    "        output_text.append({\n",
    "            \"page_number\": page_number,\n",
    "            \"text\": extract_text_from_pdf(work_dir + filename).split(\"\\n\")\n",
    "        })\n",
    "\n",
    "# Sort the text by page number\n",
    "output_text.sort(key=lambda x: x[\"page_number\"])\n",
    "\n",
    "# Remove any pages that contain nothing\n",
    "output_text = [page for page in output_text if page[\"text\"]]\n",
    "\n",
    "# Remove any pages that contain only empty lines\n",
    "output_text = [page for page in output_text if any([line for line in page[\"text\"] if line])]\n",
    "\n",
    "# Compare the first 6 lines from each page against the first 10 lines from every other page, if more than 50% of the characters match, then assume that the line is a header and remove it and all the matching lines from the other pages.\n",
    "for i in range(len(output_text)):\n",
    "    for j in range(len(output_text)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for line in output_text[i][\"text\"][:6]:\n",
    "            matching_characters = 0\n",
    "            for other_line in output_text[j][\"text\"][:6]:\n",
    "                # Calculate the number of characters that match\n",
    "                matching_characters = sum([1 for char1, char2 in zip(line, other_line) if char1 == char2])\n",
    "                # If more than 50% of the characters match, then assume that the line is a header and remove it and all the matching lines from the other pages\n",
    "                if matching_characters / len(line) > 0.5:\n",
    "                    # Replace line with an empty string\n",
    "                    output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "            if matching_characters / len(line) > 0.5:\n",
    "                output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "            # If the line is just numbers, then remove it\n",
    "            if re.match(r\"^\\d+$\", line):\n",
    "                output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "# Do the same as above, but for the last 6 lines of each page\n",
    "for i in track(range(len(output_text))):\n",
    "    for j in range(len(output_text)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for line in output_text[i][\"text\"][-6:]:\n",
    "            matching_characters = 0\n",
    "            for other_line in output_text[j][\"text\"][-6:]:\n",
    "                matching_characters = sum([1 for char1, char2 in zip(line, other_line) if char1 == char2])\n",
    "                if matching_characters / len(line) > 0.5:\n",
    "                    output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "            if matching_characters / len(line) > 0.5:\n",
    "                output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "            # If the line is just numbers, then remove it\n",
    "            if re.match(r\"^\\d+$\", line):\n",
    "                output_text[i][\"text\"] = [l for l in output_text[i][\"text\"] if l != line]\n",
    "\n",
    "           \n",
    "# Join each line with a newline character and each page with a triple newline character\n",
    "output_text = \"\\n\\n\\n\".join([\"\\n\".join(page[\"text\"]) for page in output_text])\n",
    "\n",
    "# Use structml to convert the text into a structured format\n",
    "# output_text = line_heal.parse(output_text, verbose=True)\n",
    "\n",
    "print(output_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
